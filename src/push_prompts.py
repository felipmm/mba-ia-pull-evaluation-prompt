"""
Script para fazer push de prompts otimizados ao LangSmith Prompt Hub.

Este script:
1. L√™ os prompts otimizados de prompts/bug_to_user_story_v2.yml
2. Valida os prompts
3. Faz push P√öBLICO para o LangSmith Hub
4. Adiciona metadados (tags, descri√ß√£o, t√©cnicas utilizadas)

SIMPLIFICADO: C√≥digo mais limpo e direto ao ponto.
"""

import os
import sys
from dotenv import load_dotenv
from langchain import hub
from langchain_core.prompts import ChatPromptTemplate
from utils import load_yaml, check_env_vars, print_section_header

load_dotenv()


def push_prompt_to_langsmith(prompt_name: str, prompt_data: dict) -> bool:
    """
    Faz push do prompt otimizado para o LangSmith Hub (P√öBLICO).

    Args:
        prompt_name: Nome do prompt
        prompt_data: Dados do prompt

    Returns:
        True se sucesso, False caso contr√°rio
    """
    try:
        # Extrair componentes do prompt
        system_prompt = prompt_data.get("system_prompt", "")
        user_prompt = prompt_data.get("user_prompt", "{bug_report}")
        description = prompt_data.get("description", "Prompt otimizado para bug to user story")
        version = prompt_data.get("version", "v2")
        tags = prompt_data.get("tags", [])
        techniques = prompt_data.get("techniques", [])

        # Criar nome do prompt (usar apenas o nome base, o tenant ser√° detectado da credencial)
        # Se necess√°rio especificar tenant, use: "username/bug_to_user_story_v2"
        prompt_full_name = f"bug_to_user_story_{version}"

        # Criar prompt template usando LangChain
        prompt_template = ChatPromptTemplate.from_messages(
            [
                ("system", system_prompt),
                ("human", user_prompt),
            ]
        )

        # Fazer push para LangSmith Hub
        print(f"üì§ Fazendo push do prompt: {prompt_full_name}")
        pushed_prompt = hub.push(
            prompt_full_name,
            prompt_template,
        )
        # Nota: Voc√™ pode tornar o prompt p√∫blico no dashboard do LangSmith clicando no √≠cone de cadeado

        print(f"‚úÖ Prompt enviado com sucesso para o LangSmith Hub!")
        print(f"   Nome: {prompt_full_name}")
        print(f"   Vers√£o: {version}")
        print(f"   Tags: {', '.join(tags)}")
        print(f"   T√©cnicas aplicadas: {len(techniques)}")

        return True

    except Exception as e:
        print(f"‚ùå Erro ao fazer push do prompt: {str(e)}")
        return False


def validate_prompt(prompt_data: dict) -> tuple[bool, list]:
    """
    Valida estrutura b√°sica de um prompt (vers√£o simplificada).

    Args:
        prompt_data: Dados do prompt

    Returns:
        (is_valid, errors) - Tupla com status e lista de erros
    """
    errors = []

    # Verificar campos obrigat√≥rios
    if not prompt_data.get("system_prompt"):
        errors.append("‚ùå Campo 'system_prompt' est√° vazio")

    if not prompt_data.get("user_prompt"):
        errors.append("‚ùå Campo 'user_prompt' est√° vazio")

    if not prompt_data.get("description"):
        errors.append("‚ùå Campo 'description' est√° vazio")

    if not prompt_data.get("version"):
        errors.append("‚ùå Campo 'version' est√° vazio")

    # Verificar tamanho m√≠nimo do system_prompt
    system_prompt = prompt_data.get("system_prompt", "")
    if len(system_prompt) < 200:
        errors.append(f"‚ö†Ô∏è  system_prompt muito curto ({len(system_prompt)} caracteres, esperado > 200)")

    # Verificar se h√° t√©cnicas listadas
    techniques = prompt_data.get("techniques", [])
    if not techniques or len(techniques) < 2:
        errors.append(f"‚ö†Ô∏è  Esperado >= 2 t√©cnicas, encontradas {len(techniques)}")

    is_valid = len(errors) == 0
    return is_valid, errors


def main():
    """Fun√ß√£o principal"""
    print_section_header("üöÄ PUSH DE PROMPTS OTIMIZADOS PARA LANGSMITH")

    # Verificar vari√°veis de ambiente
    required_vars = ["LANGSMITH_API_KEY", "USERNAME_LANGSMITH_HUB"]
    if not check_env_vars(required_vars):
        print("‚ùå Vari√°veis de ambiente n√£o configuradas!")
        return 1

    # Carregar prompt otimizado
    prompt_path = "prompts/bug_to_user_story_v2.yml"
    prompts = load_yaml(prompt_path)

    if not prompts:
        print(f"‚ùå Erro ao carregar {prompt_path}")
        return 1

    # Extrair prompt v2
    prompt_v2 = prompts.get("bug_to_user_story_v2")
    if not prompt_v2:
        print("‚ùå Prompt 'bug_to_user_story_v2' n√£o encontrado no YAML")
        return 1

    # Validar prompt
    is_valid, errors = validate_prompt(prompt_v2)

    if not is_valid:
        print("\nüìã Erros de valida√ß√£o encontrados:")
        for error in errors:
            print(f"  {error}")
        print()

    # Mostrar resumo do prompt
    print("\nüìä Resumo do Prompt:")
    print(f"  Descri√ß√£o: {prompt_v2.get('description', 'N/A')}")
    print(f"  Vers√£o: {prompt_v2.get('version', 'N/A')}")
    print(f"  Tags: {', '.join(prompt_v2.get('tags', []))}")
    print(f"  T√©cnicas: {len(prompt_v2.get('techniques', []))} aplicadas")
    print()

    # Fazer push do prompt
    success = push_prompt_to_langsmith("bug_to_user_story_v2", prompt_v2)

    if success:
        print("\n‚úÖ SUCESSO! Prompt v2 foi enviado para o LangSmith Prompt Hub (P√öBLICO)")
        print("üìç Voc√™ pode acess√°-lo em: https://smith.langchain.com/hub")
        return 0
    else:
        print("\n‚ùå FALHA! N√£o foi poss√≠vel enviar o prompt para o LangSmith")
        return 1


if __name__ == "__main__":
    sys.exit(main())
